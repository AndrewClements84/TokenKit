# ğŸ§  TokenKit

> **TokenKit** â€” A lightweight .NET 8.0 library and CLI tool for unified **tokenization**, **validation**, and **model registry management** across multiple LLM providers (OpenAI, Anthropic, Gemini, etc.)

---

## âœ¨ Features

| Category | Description |
|-----------|-------------|
| ğŸ”¢ **Tokenization** | Analyze text or files and count tokens using provider-specific encodings |
| ğŸ’° **Cost Estimation** | Automatically calculate estimated API cost based on token usage |
| âœ… **Prompt Validation** | Validate that prompts fit within model context limits |
| ğŸ”„ **Model Registry** | Maintain up-to-date model metadata (`maxTokens`, pricing, encodings, etc.) |
| ğŸ§© **CLI & SDK** | Use TokenKit as a .NET library *or* a standalone global CLI |
| ğŸ“¦ **Self-contained** | All data stored in `Registry/models.data.json`, auto-updated via command |

---

## âš™ï¸ Installation

### ğŸ“¦ NuGet (Library use)
```bash
dotnet add package TokenKit
```

### ğŸ§° Global CLI Tool
```bash
dotnet tool install -g TokenKit
```

---

## ğŸš€ Quick Start (CLI)

Analyze, validate, or update model data directly from your terminal.

### 1ï¸âƒ£ Analyze Inline Text
```bash
tokenkit analyze "Hello from TokenKit!" --model gpt-4o
```

**Output:**
```json
{
  "Model": "gpt-4o",
  "Provider": "OpenAI",
  "TokenCount": 4,
  "EstimatedCost": 0.00002,
  "Valid": true
}
```

---

### 2ï¸âƒ£ Analyze File Input
```bash
tokenkit analyze prompt.txt --model claude-3
```

---

### 3ï¸âƒ£ Pipe Input (stdin)
```bash
echo "This is piped text input" | tokenkit analyze --model gpt-4o
```

---

### 4ï¸âƒ£ Validate Prompt
```bash
tokenkit validate "A very long prompt to validate" --model gpt-4o
```

**Output:**
```json
{
  "IsValid": true,
  "Message": "OK"
}
```

---

### 5ï¸âƒ£ Update Model Data

#### Default Update
Fetch the latest built-in model metadata:
```bash
tokenkit update-models
```

#### Update from JSON (stdin)
Pipe a JSON file with model specs:
```bash
cat newmodels.json | tokenkit update-models
```

**Example `newmodels.json`:**
```json
[
  {
    "Id": "gpt-4o-mini",
    "Provider": "OpenAI",
    "MaxTokens": 64000,
    "InputPricePer1K": 0.002,
    "OutputPricePer1K": 0.01,
    "Encoding": "cl100k_base"
  }
]
```

---

## ğŸ§© Model Registry

TokenKit stores all known model information in:

```
src/TokenKit/Registry/models.data.json
```

Each entry contains:
```json
{
  "Id": "gpt-4o",
  "Provider": "OpenAI",
  "MaxTokens": 128000,
  "InputPricePer1K": 0.005,
  "OutputPricePer1K": 0.015,
  "Encoding": "cl100k_base"
}
```

---

## ğŸ§® CLI Command Reference

| Command | Description |
|----------|--------------|
| `tokenkit analyze "<text | path>" --model <model-id>` | Analyze and count tokens for inline text, file, or stdin input |
| `tokenkit validate "<text | path>" --model <model-id>` | Validate prompt against model token limits |
| `tokenkit update-models` | Update local registry using default source |
| `cat newmodels.json | tokenkit update-models` | Update registry from piped JSON |
| `tokenkit --help` | Display CLI usage guide |

---

## ğŸ§  Programmatic Use (SDK)

```csharp
using TokenKit.Registry;
using TokenKit.Services;

var model = ModelRegistry.Get("gpt-4o");
var tokenizer = new TokenizerService();

var result = tokenizer.Analyze("Hello from TokenKit!", model!.Id);
var cost = CostEstimator.Estimate(model, result.TokenCount);

Console.WriteLine($"Tokens: {result.TokenCount}, Cost: ${cost}");
```

---

## ğŸ§ª Testing

TokenKit includes an **xUnit** test suite with coverage for tokenization, cost estimation, and registry loading.

```bash
dotnet test
```

---

## ğŸ›  Project Structure

```
TokenKit/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ TokenKit/
â”‚       â”œâ”€â”€ Models/
â”‚       â”œâ”€â”€ Services/
â”‚       â”œâ”€â”€ Registry/
â”‚       â”œâ”€â”€ CLI/
â”‚       â””â”€â”€ Program.cs
â””â”€â”€ tests/
    â””â”€â”€ TokenKit.Tests/
```

---

## ğŸ—ºï¸ Roadmap

- [x] Tokenization, cost, and validation services  
- [x] CLI for `analyze`, `validate`, and `update-models`  
- [x] Stdin + file + inline input support  
- [x] Model registry auto-load and safe paths  
- [ ] Live model scraping from OpenAI / Anthropic / Gemini APIs  
- [ ] Add `tokenkit models list` command  
- [ ] Optional SharpToken / Microsoft.ML.Tokenizers integration  
- [ ] Publish stable v1.0.0 to NuGet + dotnet tool feed  

---

## ğŸ’¡ License

Licensed under the [MIT License](LICENSE).  
Â© 2025 Andrew Clements
